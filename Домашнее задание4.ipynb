{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных\n",
    "data = pd.read_csv('/spam.csv')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\дом\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\дом\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\дом\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\дом\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\дом\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.5 MB 262.6 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.0/1.5 MB 245.8 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.1/1.5 MB 328.2 kB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.1/1.5 MB 328.2 kB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.1/1.5 MB 245.8 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.1/1.5 MB 245.8 kB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.1/1.5 MB 245.8 kB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 382.3 kB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 446.4 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.2/1.5 MB 446.4 kB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 0.2/1.5 MB 414.8 kB/s eta 0:00:04\n",
      "   ------- -------------------------------- 0.3/1.5 MB 497.1 kB/s eta 0:00:03\n",
      "   --------- ------------------------------ 0.4/1.5 MB 637.7 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.4/1.5 MB 706.8 kB/s eta 0:00:02\n",
      "   ------------- -------------------------- 0.5/1.5 MB 784.0 kB/s eta 0:00:02\n",
      "   --------------- ------------------------ 0.6/1.5 MB 868.6 kB/s eta 0:00:02\n",
      "   ------------------ --------------------- 0.7/1.5 MB 954.2 kB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.7/1.5 MB 969.4 kB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.8/1.5 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 0.9/1.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.0/1.5 MB 1.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.0/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.1/1.5 MB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.1/1.5 MB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.2/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.3/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.4/1.5 MB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.4/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.5/1.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 1.2 MB/s eta 0:00:00\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.9.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Дом\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Дом\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import re\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'\\W', ' ', text)  # Удаление спецсимволов\n",
    "    text = text.lower()  # Приведение к нижнему регистру\n",
    "    words = nltk.word_tokenize(text)  # Токенизация\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in words])\n",
    "    \n",
    "#print(preprocess_text('Downloading package wordnet to'))\n",
    "data['processed_message'] = data['v2'].apply(lambda x: preprocess_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4                                  processed_message  \n",
      "0        NaN        NaN  go until jurong point crazy available only in ...  \n",
      "1        NaN        NaN                            ok lar joking wif u oni  \n",
      "2        NaN        NaN  free entry in 2 a wkly comp to win fa cup fina...  \n",
      "3        NaN        NaN        u dun say so early hor u c already then say  \n",
      "4        NaN        NaN  nah i don t think he go to usf he life around ...  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Bag of Words\n",
    "bow_vectorizer = CountVectorizer()\n",
    "X_bow = bow_vectorizer.fit_transform(data['processed_message'])\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(data['processed_message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       965\n",
      "           1       0.99      0.85      0.91       150\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "TF-IDF              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       965\n",
      "           1       1.00      0.70      0.82       150\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.85      0.90      1115\n",
      "weighted avg       0.96      0.96      0.96      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Подготовка данных\n",
    "y = data['v1'].apply(lambda x: 1 if x == 'spam' else 0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучение модели\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Прогнозирование\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Оценка модели\n",
    "print('Bag of Words'+classification_report(y_test, y_pred))\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Обучение модели\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train2, y_train2)\n",
    "\n",
    "# Прогнозирование\n",
    "y_pred2 = model2.predict(X_test2)\n",
    "\n",
    "# Оценка модели\n",
    "print('TF-IDF'+classification_report(y_test2, y_pred2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words ROC-AUC: 0.9830949913644215, F1-score: 0.9136690647482014, Accuracy: 0.97847533632287\n",
      "TF-IDF ROC-AUC: 0.9842625215889464, F1-score: 0.8235294117647058, Accuracy: 0.9596412556053812\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score\n",
    "\n",
    "# Оценка ROC-AUC\n",
    "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Bag of Words ROC-AUC: {roc_auc}, F1-score: {f1}, Accuracy: {accuracy}')\n",
    "\n",
    "roc_auc2 = roc_auc_score(y_test2, model2.predict_proba(X_test2)[:, 1])\n",
    "f1_2 = f1_score(y_test2, y_pred2)\n",
    "accuracy2 = accuracy_score(y_test2, y_pred2)\n",
    "\n",
    "print(f'TF-IDF ROC-AUC: {roc_auc2}, F1-score: {f1_2}, Accuracy: {accuracy2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
